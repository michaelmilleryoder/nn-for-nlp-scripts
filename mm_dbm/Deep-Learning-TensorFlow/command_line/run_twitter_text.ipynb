{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So can get yadlt\n",
    "import sys\n",
    "sys.path.append('/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/')\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import inspect\n",
    "import fasttext as ft\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import dbm\n",
    "import config\n",
    "import rbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vocab in words\n",
    "with open('/usr2/mamille2/twitter/data/huang2016_data/train_text_vocab_10k.txt') as f:\n",
    "    vocab = f.read().splitlines()\n",
    "    \n",
    "# Vocab embeddings\n",
    "with open('/usr2/mamille2/twitter/data/huang2016_data/train_vocab_10k_emb.pkl', 'rb') as g:\n",
    "    embs = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214999\n"
     ]
    }
   ],
   "source": [
    "# Training text, preprocessed\n",
    "with open('/usr2/mamille2/twitter/data/huang2016_data/text_train.txt') as f:\n",
    "    toks_train = [l.split() for l in f.read().splitlines()]\n",
    "    \n",
    "print(len(toks_train))\n",
    "# print(toks_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating /usr2/mamille2/twitter/data/mm_dbm/model/stored_models/ directory to save/restore models\n",
      "Creating /usr2/mamille2/twitter/data/mm_dbm/model/data/ directory to save model generated data\n",
      "Creating /usr2/mamille2/twitter/data/mm_dbm/model/logs/ directory to save tensorboard logs\n",
      "Creating /usr2/mamille2/twitter/data/mm_dbm/model/stored_models/rbm-1 directory to save/restore models\n",
      "Creating /usr2/mamille2/twitter/data/mm_dbm/model/data/rbm-1 directory to save model generated data\n",
      "Creating /usr2/mamille2/twitter/data/mm_dbm/model/logs/rbm-1 directory to save tensorboard logs\n",
      "Creating /usr2/mamille2/twitter/data/mm_dbm/model/stored_models/rbm-2 directory to save/restore models\n",
      "Creating /usr2/mamille2/twitter/data/mm_dbm/model/data/rbm-2 directory to save model generated data\n",
      "Creating /usr2/mamille2/twitter/data/mm_dbm/model/logs/rbm-2 directory to save tensorboard logs\n"
     ]
    }
   ],
   "source": [
    "# Modeled on image data\n",
    "\n",
    "model = dbm.DBM(\n",
    "    main_dir=\"/usr2/mamille2/twitter/data/huang2016_data/twitter_text_rbm\", do_pretrain=True, layers=[1024, 1024],\n",
    "    models_dir=config.models_dir, data_dir=config.data_dir, summary_dir=config.summary_dir,\n",
    "    learning_rate=[0.001, 0.001], momentum=0.9, num_epochs=[1, 1], batch_size=[64, 64],\n",
    "    stddev=0.1, verbose=1, gibbs_k=[1, 1], model_name=\"twitter_text_dbm\",\n",
    "    finetune_learning_rate=0.01, finetune_enc_act_func=[tf.nn.sigmoid, tf.nn.sigmoid],\n",
    "    finetune_dec_act_func=[tf.nn.sigmoid, tf.nn.sigmoid], finetune_num_epochs=5, finetune_batch_size=128,\n",
    "    finetune_opt='momentum', finetune_loss_func=\"mean_squared\", finetune_dropout=0.5, noise=[\"gauss\", \"bin\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 80 # Max number of tweets around 80\n",
    "\n",
    "# Construct UNK vector of average vector\n",
    "all_embs = np.array(list(embs.values())[:])\n",
    "unkvec = np.mean(all_embs, axis=0)\n",
    "\n",
    "def tweet2vec(tweet_toks, embs, max_len):\n",
    "    \"\"\" Return concatenated word embeddings from tweet tokens, padded to a max length \"\"\"\n",
    "    \n",
    "    emb_list = [embs.get(w, unkvec) for w in tweet_toks[:max_len]]\n",
    "    tweet_mat = np.pad(emb_list, ((0,max_len-len(emb_list)), (0,0)), 'constant', constant_values=0)\n",
    "    \n",
    "    return tweet_mat.flatten()\n",
    "\n",
    "# Get data dynamically so not so much RAM usage\n",
    "def tweets_embed(tweets_toks, embs, max_len):\n",
    "    \"\"\" Return word embeddings from list of tweet tokens, padded to a max length \"\"\"\n",
    "    \n",
    "    tweets_mat = [tweet2vec(tweet, embs, max_len) for tweet in tweets_toks]\n",
    "        \n",
    "    return np.array(tweets_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building train 1\n",
      "Done building train 2\n"
     ]
    }
   ],
   "source": [
    "# Pretraining phase \n",
    "# train1 = tweets_embed(toks_train[:500], embs, MAX_LEN)\n",
    "# train2 = tweets_embed(toks_train[500:1000], embs, MAX_LEN)\n",
    "train1 = tweets_embed(toks_train[:10000], embs, MAX_LEN)\n",
    "print(\"Done building train 1\")\n",
    "train2 = tweets_embed(toks_train[10000:20000], embs, MAX_LEN)\n",
    "print(\"Done building train 2\")\n",
    "# print(train1.shape)\n",
    "# print(train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer 1...\n",
      "Tensorboard logs dir for this run is /usr2/mamille2/twitter/data/mm_dbm/model/logs/rbm-1/run20\n",
      "Reconstruction loss at step 0: 0.404077\n",
      "Training layer 2...\n",
      "Tensorboard logs dir for this run is /usr2/mamille2/twitter/data/mm_dbm/model/logs/rbm-2/run19\n",
      "Reconstruction loss at step 0: 0.118569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.56180596,  0.66380399,  0.31962618, ...,  0.54801655,\n",
       "          0.43488625,  0.4274264 ],\n",
       "        [ 0.58443767,  0.57850999,  0.38086259, ...,  0.61280924,\n",
       "          0.48586884,  0.36361116],\n",
       "        [ 0.65635574,  0.63681233,  0.32367343, ...,  0.4517298 ,\n",
       "          0.50786972,  0.35507789],\n",
       "        ..., \n",
       "        [ 0.67270261,  0.62787724,  0.4213872 , ...,  0.37202278,\n",
       "          0.48151723,  0.4435603 ],\n",
       "        [ 0.40214041,  0.53491944,  0.42307886, ...,  0.48610663,\n",
       "          0.56079775,  0.37639761],\n",
       "        [ 0.66140223,  0.50370604,  0.56105483, ...,  0.35186243,\n",
       "          0.25721386,  0.3114686 ]], dtype=float32),\n",
       " array([[ 0.60677838,  0.57522899,  0.59163254, ...,  0.66177225,\n",
       "          0.55448431,  0.4701899 ],\n",
       "        [ 0.57875955,  0.64811701,  0.40937036, ...,  0.2916674 ,\n",
       "          0.61565715,  0.38740188],\n",
       "        [ 0.64729851,  0.83547252,  0.36572573, ...,  0.43609035,\n",
       "          0.55515784,  0.28614867],\n",
       "        ..., \n",
       "        [ 0.66834635,  0.70633572,  0.40181169, ...,  0.44917032,\n",
       "          0.62940776,  0.37974784],\n",
       "        [ 0.60065866,  0.76150674,  0.46228036, ...,  0.44506752,\n",
       "          0.36162031,  0.50475377],\n",
       "        [ 0.72683525,  0.74400085,  0.40905711, ...,  0.4538523 ,\n",
       "          0.41783977,  0.26742893]], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrain(train1, train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1 loaded\n",
      "Train 2 loaded\n",
      "Train 3 loaded\n",
      "Train 4 loaded\n"
     ]
    }
   ],
   "source": [
    "# Fit and save the txt-DBM parameters \n",
    "# I put save_dbm_text_params as a quick hack to save the parameters of this dbm as a numpy array\n",
    "\n",
    "# takes args train_set, train_ref, validation_set, validation_ref -- unsupervised, so just use more of the dataset\n",
    "# train1 = tweets_embed(toks_train[:500], embs, MAX_LEN)\n",
    "# train2 = tweets_embed(toks_train[500:1000], embs, MAX_LEN)\n",
    "# train3 = tweets_embed(toks_train[1000:1500], embs, MAX_LEN)\n",
    "# train4 = tweets_embed(toks_train[1500:2000], embs, MAX_LEN)\n",
    "\n",
    "# train_split = len(toks_train)//4\n",
    "train_split = 10000\n",
    "\n",
    "train1 = tweets_embed(toks_train[:train_split], embs, MAX_LEN)\n",
    "print(\"Train 1 loaded\")\n",
    "train2 = tweets_embed(toks_train[train_split:2*train_split], embs, MAX_LEN)\n",
    "print(\"Train 2 loaded\")\n",
    "train3 = tweets_embed(toks_train[2*train_split:3*train_split], embs, MAX_LEN)\n",
    "print(\"Train 3 loaded\")\n",
    "train4 = tweets_embed(toks_train[3*train_split:4*train_split], embs, MAX_LEN)\n",
    "print(\"Train 4 loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard logs dir for this run is /usr2/mamille2/twitter/data/mm_dbm/model/logs/run17\n",
      "Reconstruction loss at step 0: 0.381881\n",
      "Reconstruction loss at step 1: 0.381118\n",
      "Reconstruction loss at step 2: 0.38041\n",
      "Reconstruction loss at step 3: 0.379778\n",
      "Reconstruction loss at step 4: 0.379198\n"
     ]
    }
   ],
   "source": [
    "model.fit(train1, train2, train3, train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1 loaded\n",
      "Train 2 loaded\n",
      "Train 3 loaded\n",
      "Train 4 loaded\n"
     ]
    }
   ],
   "source": [
    "# Fit and save the txt-DBM parameters (iterative try)\n",
    "\n",
    "offset = 4 * train_split\n",
    "increment = 10000\n",
    "\n",
    "train1 = tweets_embed(toks_train[offset:offset+increment], embs, MAX_LEN)\n",
    "print(\"Train 1 loaded\")\n",
    "train2 = tweets_embed(toks_train[offset+increment:offset+2*increment], embs, MAX_LEN)\n",
    "print(\"Train 2 loaded\")\n",
    "train3 = tweets_embed(toks_train[offset+2*increment:offset+3*increment], embs, MAX_LEN)\n",
    "print(\"Train 3 loaded\")\n",
    "train4 = tweets_embed(toks_train[offset+3*increment:offset+4*increment], embs, MAX_LEN)\n",
    "print(\"Train 4 loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value enc-w-0\n\t [[Node: enc-w-0/read = Identity[T=DT_FLOAT, _class=[\"loc:@enc-w-0\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](enc-w-0)]]\n\nCaused by op 'enc-w-0/read', defined at:\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-10d00bd4b421>\", line 1, in <module>\n    model.fit(train1, train2, train3, train4)\n  File \"/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/command_line/unsupervised_model.py\", line 44, in fit\n    self.build_model(train_set.shape[1])\n  File \"/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/command_line/dbm.py\", line 172, in build_model\n    self._create_variables(n_features)\n  File \"/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/command_line/dbm.py\", line 207, in _create_variables\n    self._create_variables_pretrain()\n  File \"/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/command_line/dbm.py\", line 240, in _create_variables_pretrain\n    self.encoding_w_[l], name='enc-w-{}'.format(l))\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 315, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1490, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value enc-w-0\n\t [[Node: enc-w-0/read = Identity[T=DT_FLOAT, _class=[\"loc:@enc-w-0\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](enc-w-0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value enc-w-0\n\t [[Node: enc-w-0/read = Identity[T=DT_FLOAT, _class=[\"loc:@enc-w-0\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](enc-w-0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ffa771b60d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_previous_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDone with {} instances\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mincrement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/command_line/unsupervised_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_set, train_ref, validation_set, validation_ref, restore_previous_model, graph)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_session\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_tf_utilities_and_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_previous_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 self._train_model(\n\u001b[1;32m     48\u001b[0m                     train_set, train_ref, validation_set, validation_ref)\n",
      "\u001b[0;32m/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/yadlt/core/model.py\u001b[0m in \u001b[0;36m_initialize_tf_utilities_and_ops\u001b[0;34m(self, restore_previous_model)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_previous_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value enc-w-0\n\t [[Node: enc-w-0/read = Identity[T=DT_FLOAT, _class=[\"loc:@enc-w-0\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](enc-w-0)]]\n\nCaused by op 'enc-w-0/read', defined at:\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-10d00bd4b421>\", line 1, in <module>\n    model.fit(train1, train2, train3, train4)\n  File \"/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/command_line/unsupervised_model.py\", line 44, in fit\n    self.build_model(train_set.shape[1])\n  File \"/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/command_line/dbm.py\", line 172, in build_model\n    self._create_variables(n_features)\n  File \"/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/command_line/dbm.py\", line 207, in _create_variables\n    self._create_variables_pretrain()\n  File \"/usr2/mamille2/nn4nlp-scripts/mm_dbm/Deep-Learning-TensorFlow/command_line/dbm.py\", line 240, in _create_variables_pretrain\n    self.encoding_w_[l], name='enc-w-{}'.format(l))\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 315, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1490, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value enc-w-0\n\t [[Node: enc-w-0/read = Identity[T=DT_FLOAT, _class=[\"loc:@enc-w-0\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](enc-w-0)]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train1, train2, train3, train4, restore_previous_model=True)\n",
    "print(\"\\nDone with {} instances\".format(offset + 4*increment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save out model params\n",
    "outpath = '/usr2/mamille2/twitter/data/mm_dbm/model/text_dbms_layer_{}_{}.npy'\n",
    "\n",
    "for i in range(len(model.rbms)):\n",
    "    for p in ['W', 'bh_', 'bv_']: # not sure whether uses bh or bv\n",
    "        np.save(outpath.format(i, p), model.rbms[0].get_model_parameters(graph=model.rbm_graphs[0])[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1024)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rbms[0].get_model_parameters(graph=model.rbm_graphs[0])['W'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rbms[1].get_model_parameters(graph=model.rbm_graphs[1])['W'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rbms[0].get_model_parameters(graph=model.rbm_graphs[0])['bh_'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rbms[0].get_model_parameters(graph=model.rbm_graphs[0])['bv_'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format tweet text as word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'created_at', 'in_reply_to_status_id', 'lang',\n",
       "       'retweet_count', 'user_id', 'user_screen_name', 'user_name', 'text',\n",
       "       'text_no_tags', 'tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_pickle('/usr2/mamille2/twitter/data/huang2016_data/huang2016_train.pkl')\n",
    "valid_data = pd.read_pickle('/usr2/mamille2/twitter/data/huang2016_data/huang2016_valid.pkl')\n",
    "test_data = pd.read_pickle('/usr2/mamille2/twitter/data/huang2016_data/huang2016_test.pkl')\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-9975ffdddfc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize word embeddings, make lookup table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwembed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr2/mamille2/discourse_connectives/en_wiki_stanford_model_300.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_no_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:66124)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-9975ffdddfc1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize word embeddings, make lookup table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwembed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr2/mamille2/discourse_connectives/en_wiki_stanford_model_300.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_no_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m     return [token for sent in sent_tokenize(text, language)\n\u001b[0m\u001b[1;32m    110\u001b[0m             for token in _treebank_word_tokenize(sent)]\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     return [token for sent in sent_tokenize(text, language)\n\u001b[0;32m--> 110\u001b[0;31m             for token in _treebank_word_tokenize(sent)]\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/nltk/tokenize/treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr' \\1 \\2 '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr' \\1 \\2 '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize word embeddings, make lookup table\n",
    "wembed = ft.load_model('/usr2/mamille2/discourse_connectives/en_wiki_stanford_model_300.bin')\n",
    "toks = train_data['text_no_tags'].map(lambda x: word_tokenize(x.lower())).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'amp', 'https', 'http', '...', '``', \"''\", \"'s\"]\n"
     ]
    }
   ],
   "source": [
    "custom_stops = ['amp', 'https', 'http', '...', '``', \"''\", \"'s\"]\n",
    "stops = nltk.corpus.stopwords.words('english') + [c for c in string.punctuation] + custom_stops\n",
    "\n",
    "# Stop patterns--reject if matches athg in them\n",
    "stop_pats = ['…', 't.co']\n",
    "\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216704"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks_agg = sorted([wd for d in toks for wd in d if not wd in stops and not any([s in wd for s in stop_pats])])\n",
    "toks_ctr = Counter(toks_agg)\n",
    "vocab_all = sorted(toks_ctr.keys())\n",
    "len(vocab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_10k = sorted([w for w,_ in toks_ctr.most_common(10000)])\n",
    "len(vocab_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rt', 96229),\n",
       " ('via', 10616),\n",
       " ('new', 9388),\n",
       " (\"n't\", 7912),\n",
       " ('get', 5444),\n",
       " ('today', 5397),\n",
       " ('one', 5258),\n",
       " ('day', 4785),\n",
       " ('time', 4752),\n",
       " ('us', 4655),\n",
       " ('great', 4589),\n",
       " ('love', 4396),\n",
       " ('like', 4301),\n",
       " ('good', 3868),\n",
       " ('see', 3486),\n",
       " ('best', 3399),\n",
       " ('follow', 3389),\n",
       " ('gt', 3346),\n",
       " ('people', 3322),\n",
       " ('2', 3303),\n",
       " ('world', 3141),\n",
       " ('make', 3134),\n",
       " ('need', 3069),\n",
       " ('back', 3064),\n",
       " ('check', 3053),\n",
       " ('help', 2999),\n",
       " ('know', 2868),\n",
       " ('first', 2859),\n",
       " ('go', 2778),\n",
       " (\"'m\", 2766),\n",
       " (\"'re\", 2766),\n",
       " ('2016', 2762),\n",
       " ('thanks', 2700),\n",
       " ('free', 2691),\n",
       " ('want', 2574),\n",
       " ('1', 2507),\n",
       " ('last', 2494),\n",
       " ('year', 2489),\n",
       " ('live', 2406),\n",
       " ('3', 2405),\n",
       " ('win', 2393),\n",
       " ('work', 2386),\n",
       " ('4', 2378),\n",
       " ('week', 2346),\n",
       " ('happy', 2333),\n",
       " ('5', 2283),\n",
       " ('life', 2263),\n",
       " ('may', 2221),\n",
       " ('way', 2080),\n",
       " ('next', 2069),\n",
       " ('take', 2067),\n",
       " ('says', 2066),\n",
       " ('would', 2062),\n",
       " ('top', 2054),\n",
       " ('read', 2053),\n",
       " ('right', 2053),\n",
       " ('video', 2051),\n",
       " ('could', 2030),\n",
       " ('thank', 2011),\n",
       " ('big', 1981),\n",
       " ('news', 1943),\n",
       " ('tonight', 1931),\n",
       " ('look', 1930),\n",
       " ('business', 1919),\n",
       " ('watch', 1919),\n",
       " ('10', 1908),\n",
       " ('still', 1877),\n",
       " ('got', 1866),\n",
       " ('home', 1866),\n",
       " ('find', 1854),\n",
       " ('game', 1844),\n",
       " ('w/', 1769),\n",
       " ('think', 1765),\n",
       " ('let', 1762),\n",
       " ('please', 1747),\n",
       " ('night', 1738),\n",
       " ('much', 1727),\n",
       " ('use', 1722),\n",
       " ('looking', 1717),\n",
       " ('going', 1714),\n",
       " ('join', 1708),\n",
       " ('support', 1683),\n",
       " ('show', 1673),\n",
       " ('come', 1659),\n",
       " ('women', 1656),\n",
       " ('years', 1656),\n",
       " ('social', 1638),\n",
       " ('ca', 1632),\n",
       " (\"'ve\", 1625),\n",
       " ('never', 1605),\n",
       " ('team', 1605),\n",
       " ('morning', 1591),\n",
       " ('–', 1578),\n",
       " ('every', 1563),\n",
       " ('media', 1497),\n",
       " ('better', 1482),\n",
       " ('things', 1464),\n",
       " ('say', 1463),\n",
       " (\"'ll\", 1440),\n",
       " ('really', 1428),\n",
       " ('learn', 1414),\n",
       " ('everyone', 1394),\n",
       " ('made', 1392),\n",
       " ('many', 1379),\n",
       " ('change', 1361),\n",
       " ('man', 1350),\n",
       " ('city', 1340),\n",
       " ('u', 1335),\n",
       " ('story', 1333),\n",
       " ('another', 1327),\n",
       " ('season', 1324),\n",
       " ('start', 1313),\n",
       " ('ever', 1312),\n",
       " ('book', 1300),\n",
       " ('must', 1299),\n",
       " ('well', 1294),\n",
       " ('tips', 1288),\n",
       " ('--', 1283),\n",
       " ('amazing', 1268),\n",
       " ('always', 1259),\n",
       " ('..', 1251),\n",
       " ('part', 1247),\n",
       " ('twitter', 1243),\n",
       " ('vote', 1241),\n",
       " ('real', 1235),\n",
       " ('beautiful', 1223),\n",
       " ('followers', 1202),\n",
       " ('give', 1197),\n",
       " ('future', 1170),\n",
       " ('open', 1169),\n",
       " ('ready', 1165),\n",
       " ('two', 1164),\n",
       " ('6', 1161),\n",
       " ('little', 1151),\n",
       " ('stop', 1139),\n",
       " ('keep', 1137),\n",
       " ('report', 1131),\n",
       " ('end', 1130),\n",
       " ('7', 1124),\n",
       " ('weekend', 1118),\n",
       " ('tomorrow', 1108),\n",
       " ('getting', 1107),\n",
       " ('latest', 1099),\n",
       " ('even', 1098),\n",
       " ('data', 1089),\n",
       " ('days', 1075),\n",
       " ('state', 1062),\n",
       " ('set', 1056),\n",
       " ('visit', 1055),\n",
       " ('coming', 1039),\n",
       " ('listen', 1038),\n",
       " ('family', 1036),\n",
       " ('2015', 1021),\n",
       " ('april', 1018),\n",
       " ('ways', 1009),\n",
       " ('play', 1005),\n",
       " ('music', 993),\n",
       " ('trump', 988),\n",
       " ('high', 977),\n",
       " ('hope', 973),\n",
       " ('house', 967),\n",
       " ('photo', 963),\n",
       " ('post', 962),\n",
       " ('online', 959),\n",
       " ('share', 958),\n",
       " ('talk', 957),\n",
       " ('marketing', 951),\n",
       " ('power', 949),\n",
       " ('health', 946),\n",
       " ('fun', 944),\n",
       " ('making', 941),\n",
       " ('following', 937),\n",
       " ('since', 934),\n",
       " ('friends', 932),\n",
       " ('meet', 932),\n",
       " ('president', 929),\n",
       " ('sure', 929),\n",
       " ('blog', 923),\n",
       " ('old', 921),\n",
       " ('money', 913),\n",
       " ('fans', 911),\n",
       " ('million', 907),\n",
       " ('away', 899),\n",
       " ('retweet', 899),\n",
       " ('job', 897),\n",
       " ('using', 895),\n",
       " ('needs', 893),\n",
       " ('awesome', 892),\n",
       " ('full', 892),\n",
       " ('uk', 884),\n",
       " ('food', 883),\n",
       " ('event', 880),\n",
       " ('kids', 879),\n",
       " ('place', 878),\n",
       " ('call', 874),\n",
       " ('long', 871),\n",
       " ('school', 858),\n",
       " ('around', 856),\n",
       " ('stories', 856),\n",
       " ('thing', 856),\n",
       " ('done', 850),\n",
       " ('makes', 850),\n",
       " ('run', 845),\n",
       " ('global', 844),\n",
       " ('party', 833),\n",
       " ('working', 833),\n",
       " ('de', 826),\n",
       " ('miss', 826),\n",
       " ('without', 819),\n",
       " ('100', 816),\n",
       " ('something', 814),\n",
       " ('save', 812),\n",
       " ('tell', 805),\n",
       " ('enter', 803),\n",
       " ('nice', 803),\n",
       " ('chance', 802),\n",
       " ('also', 800),\n",
       " ('black', 800),\n",
       " ('try', 794),\n",
       " ('google', 788),\n",
       " ('vs', 774),\n",
       " ('national', 772),\n",
       " ('yes', 772),\n",
       " ('1st', 770),\n",
       " ('deal', 758),\n",
       " ('police', 753),\n",
       " ('summer', 750),\n",
       " ('bad', 747),\n",
       " ('art', 745),\n",
       " ('easy', 743),\n",
       " ('children', 741),\n",
       " ('yet', 740),\n",
       " ('looks', 739),\n",
       " ('20', 738),\n",
       " ('said', 738),\n",
       " ('found', 736),\n",
       " ('special', 736),\n",
       " ('app', 735),\n",
       " ('series', 733),\n",
       " ('congrats', 730),\n",
       " ('march', 729),\n",
       " ('everything', 727),\n",
       " ('feel', 724),\n",
       " ('8', 722),\n",
       " ('favorite', 722),\n",
       " ('fight', 720),\n",
       " ('watching', 718),\n",
       " ('times', 717),\n",
       " ('service', 716),\n",
       " ('important', 715),\n",
       " ('design', 714),\n",
       " ('lt', 710),\n",
       " ('plan', 707),\n",
       " ('wait', 706),\n",
       " ('london', 704),\n",
       " ('water', 704),\n",
       " ('guide', 702),\n",
       " ('list', 701),\n",
       " ('friday', 700),\n",
       " ('sales', 700),\n",
       " ('gets', 695),\n",
       " ('final', 692),\n",
       " ('true', 692),\n",
       " ('experience', 691),\n",
       " ('nothing', 691),\n",
       " ('project', 691),\n",
       " ('remember', 688),\n",
       " ('welcome', 687),\n",
       " ('young', 687),\n",
       " ('info', 685),\n",
       " ('public', 684),\n",
       " ('put', 684),\n",
       " ('students', 681),\n",
       " ('justinbieber', 677),\n",
       " ('white', 677),\n",
       " ('god', 676),\n",
       " ('sign', 676),\n",
       " ('hard', 671),\n",
       " ('heart', 671),\n",
       " ('available', 669),\n",
       " ('bill', 667),\n",
       " ('care', 665),\n",
       " ('forward', 663),\n",
       " ('spring', 663),\n",
       " ('group', 659),\n",
       " ('anyone', 658),\n",
       " ('left', 658),\n",
       " ('stay', 658),\n",
       " ('proud', 657),\n",
       " ('company', 656),\n",
       " ('perfect', 653),\n",
       " ('jobs', 650),\n",
       " ('campaign', 648),\n",
       " ('case', 647),\n",
       " ('market', 645),\n",
       " ('face', 643),\n",
       " ('study', 639),\n",
       " ('action', 638),\n",
       " ('create', 638),\n",
       " ('someone', 638),\n",
       " ('community', 637),\n",
       " ('government', 637),\n",
       " ('history', 637),\n",
       " ('red', 637),\n",
       " ('country', 636),\n",
       " ('12', 635),\n",
       " ('review', 635),\n",
       " ('america', 634),\n",
       " ('behind', 633),\n",
       " ('hey', 630),\n",
       " ('lead', 630),\n",
       " ('taking', 627),\n",
       " ('na', 622),\n",
       " ('ago', 621),\n",
       " ('digital', 619),\n",
       " ('success', 618),\n",
       " ('together', 618),\n",
       " ('obama', 617),\n",
       " ('soon', 617),\n",
       " ('content', 614),\n",
       " ('9', 612),\n",
       " ('mobile', 612),\n",
       " ('photos', 611),\n",
       " ('update', 611),\n",
       " (\"'d\", 606),\n",
       " ('key', 606),\n",
       " ('killed', 606),\n",
       " ('building', 605),\n",
       " ('three', 604),\n",
       " ('bring', 602),\n",
       " ('small', 602),\n",
       " ('hear', 601),\n",
       " ('cool', 600),\n",
       " ('lost', 600),\n",
       " ('might', 600),\n",
       " ('15', 599),\n",
       " ('girl', 599),\n",
       " ('seen', 599),\n",
       " ('talking', 598),\n",
       " ('security', 596),\n",
       " ('u.s.', 596),\n",
       " ('men', 595),\n",
       " ('energy', 594),\n",
       " ('facebook', 593),\n",
       " ('tweet', 593),\n",
       " ('w', 593),\n",
       " ('local', 592),\n",
       " ('50', 591),\n",
       " ('woman', 589),\n",
       " ('un', 588),\n",
       " ('industry', 585),\n",
       " ('30', 584),\n",
       " ('tech', 584),\n",
       " ('goal', 583),\n",
       " ('head', 583),\n",
       " ('hot', 583),\n",
       " ('build', 582),\n",
       " ('rights', 581),\n",
       " ('takes', 581),\n",
       " ('tv', 580),\n",
       " ('shows', 579),\n",
       " ('become', 576),\n",
       " ('hit', 576),\n",
       " ('less', 576),\n",
       " ('oh', 573),\n",
       " ('sunday', 571),\n",
       " ('fast', 570),\n",
       " ('interview', 570),\n",
       " ('used', 569),\n",
       " ('monday', 568),\n",
       " ('excited', 567),\n",
       " ('believe', 565),\n",
       " ('enjoy', 564),\n",
       " ('pay', 564),\n",
       " ('gain', 562),\n",
       " ('development', 561),\n",
       " ('human', 561),\n",
       " ('baby', 559),\n",
       " ('worth', 559),\n",
       " ('early', 558),\n",
       " ('11', 557),\n",
       " ('apple', 555),\n",
       " ('others', 554),\n",
       " ('comes', 552),\n",
       " ('else', 552),\n",
       " ('office', 552),\n",
       " ('pm', 552),\n",
       " ('super', 552),\n",
       " ('light', 551),\n",
       " ('park', 550),\n",
       " ('meeting', 549),\n",
       " ('research', 549),\n",
       " ('playing', 548),\n",
       " ('far', 546),\n",
       " ('star', 545),\n",
       " ('training', 544),\n",
       " ('wants', 544),\n",
       " ('john', 543),\n",
       " ('already', 541),\n",
       " ('daily', 541),\n",
       " ('interesting', 541),\n",
       " ('games', 540),\n",
       " ('buy', 538),\n",
       " ('enough', 537),\n",
       " ('goes', 537),\n",
       " ('search', 534),\n",
       " ('—', 534),\n",
       " ('lot', 533),\n",
       " ('international', 532),\n",
       " ('release', 532),\n",
       " ('green', 530),\n",
       " ('war', 530),\n",
       " ('death', 529),\n",
       " ('finally', 529),\n",
       " ('move', 529),\n",
       " ('ask', 524),\n",
       " ('words', 524),\n",
       " ('fire', 522),\n",
       " ('road', 520),\n",
       " ('friend', 519),\n",
       " ('guys', 519),\n",
       " ('leaders', 519),\n",
       " ('line', 519),\n",
       " ('hours', 518),\n",
       " ('wow', 518),\n",
       " ('american', 515),\n",
       " ('month', 515),\n",
       " ('view', 515),\n",
       " ('court', 513),\n",
       " ('moment', 512),\n",
       " ('running', 511),\n",
       " ('breaking', 510),\n",
       " ('trying', 508),\n",
       " ('song', 506),\n",
       " ('article', 505),\n",
       " ('huge', 505),\n",
       " ('second', 504),\n",
       " ('record', 503),\n",
       " ('growth', 502),\n",
       " ('web', 498),\n",
       " ('sale', 497),\n",
       " ('saturday', 497),\n",
       " ('shot', 497),\n",
       " ('wo', 497),\n",
       " ('birthday', 496),\n",
       " ('program', 495),\n",
       " ('united', 495),\n",
       " ('yesterday', 494),\n",
       " ('conference', 493),\n",
       " ('beat', 492),\n",
       " ('site', 492),\n",
       " ('dead', 491),\n",
       " ('eu', 491),\n",
       " ('person', 489),\n",
       " ('it’s', 486),\n",
       " ('official', 486),\n",
       " ('starting', 486),\n",
       " ('travel', 486),\n",
       " ('gift', 485),\n",
       " ('girls', 485),\n",
       " ('blue', 484),\n",
       " ('brand', 484),\n",
       " ('reading', 484),\n",
       " ('thinking', 483),\n",
       " ('ahead', 482),\n",
       " ('giving', 480),\n",
       " ('congratulations', 478),\n",
       " ('don’t', 478),\n",
       " ('started', 478),\n",
       " ('mind', 477),\n",
       " ('reasons', 477),\n",
       " ('past', 473),\n",
       " ('car', 472),\n",
       " ('film', 472),\n",
       " ('law', 472),\n",
       " ('ad', 471),\n",
       " ('learning', 471),\n",
       " ('name', 471),\n",
       " ('25', 470),\n",
       " ('performance', 470),\n",
       " ('system', 470),\n",
       " ('race', 469),\n",
       " ('services', 469),\n",
       " ('strong', 469),\n",
       " ('companies', 468),\n",
       " ('stand', 468),\n",
       " ('air', 466),\n",
       " ('child', 465),\n",
       " ('canada', 463),\n",
       " ('south', 463),\n",
       " ('close', 462),\n",
       " ('forget', 460),\n",
       " ('hello', 460),\n",
       " ('street', 460),\n",
       " ('trip', 458),\n",
       " ('talks', 456),\n",
       " ('almost', 454),\n",
       " ('award', 452),\n",
       " ('india', 452),\n",
       " ('pick', 452),\n",
       " ('turn', 452),\n",
       " ('ideas', 451),\n",
       " ('minutes', 451),\n",
       " ('leader', 450),\n",
       " ('website', 450),\n",
       " ('amazon', 449),\n",
       " ('peace', 448),\n",
       " ('youtube', 448),\n",
       " ('details', 447),\n",
       " ('climate', 446),\n",
       " ('trade', 446),\n",
       " ('members', 445),\n",
       " ('oil', 442),\n",
       " ('single', 442),\n",
       " ('winning', 442),\n",
       " ('fall', 440),\n",
       " ('york', 440),\n",
       " ('education', 439),\n",
       " ('r', 439),\n",
       " ('x', 438),\n",
       " ('point', 437),\n",
       " ('wins', 437),\n",
       " ('north', 436),\n",
       " ('challenge', 435),\n",
       " ('improve', 435),\n",
       " ('mean', 435),\n",
       " ('direction', 433),\n",
       " ('♫', 433),\n",
       " ('realdonaldtrump', 432),\n",
       " ('retweeted', 432),\n",
       " ('n', 431),\n",
       " ('states', 431),\n",
       " ('impact', 430),\n",
       " ('manager', 430),\n",
       " ('pls', 429),\n",
       " ('mother', 428),\n",
       " ('dream', 426),\n",
       " ('former', 426),\n",
       " ('justin', 426),\n",
       " ('pretty', 425),\n",
       " ('short', 425),\n",
       " ('steps', 425),\n",
       " ('europe', 422),\n",
       " ('room', 421),\n",
       " ('hillary', 420),\n",
       " ('increase', 420),\n",
       " ('lives', 420),\n",
       " ('strategy', 420),\n",
       " ('word', 420),\n",
       " ('fan', 419),\n",
       " ('space', 419),\n",
       " ('thought', 419),\n",
       " ('access', 418),\n",
       " ('gold', 418),\n",
       " ('13', 417),\n",
       " ('attack', 417),\n",
       " ('biggest', 416),\n",
       " ('class', 416),\n",
       " ('iphone', 416),\n",
       " ('level', 415),\n",
       " ('living', 415),\n",
       " ('plans', 415),\n",
       " ('writing', 415),\n",
       " ('episode', 414),\n",
       " ('grow', 414),\n",
       " ('opportunity', 414),\n",
       " ('major', 413),\n",
       " ('wrong', 413),\n",
       " ('break', 412),\n",
       " ('en', 412),\n",
       " ('risk', 412),\n",
       " ('books', 411),\n",
       " ('calls', 411),\n",
       " ('lol', 411),\n",
       " ('matter', 411),\n",
       " ('west', 411),\n",
       " ('customer', 409),\n",
       " ('starts', 408),\n",
       " ('2nd', 407),\n",
       " ('near', 407),\n",
       " ('half', 406),\n",
       " ('link', 406),\n",
       " ('cc', 405),\n",
       " ('listening', 405),\n",
       " ('needed', 405),\n",
       " ('china', 404),\n",
       " ('late', 404),\n",
       " ('club', 403),\n",
       " ('network', 403),\n",
       " ('page', 403),\n",
       " ('phone', 403),\n",
       " ('awards', 402),\n",
       " ('test', 402),\n",
       " ('wind', 402),\n",
       " ('anything', 400),\n",
       " ('four', 400),\n",
       " ('radio', 400),\n",
       " ('side', 400),\n",
       " ('gop', 399),\n",
       " ('actually', 396),\n",
       " ('heard', 396),\n",
       " ('icymi', 396),\n",
       " ('policy', 396),\n",
       " ('inside', 395),\n",
       " ('sharing', 395),\n",
       " ('add', 394),\n",
       " ('internet', 393),\n",
       " ('rules', 393),\n",
       " ('technology', 392),\n",
       " ('tour', 391),\n",
       " ('prince', 390),\n",
       " ('five', 389),\n",
       " ('tax', 389),\n",
       " ('different', 388),\n",
       " ('winner', 388),\n",
       " ('across', 387),\n",
       " ('came', 387),\n",
       " ('countries', 387),\n",
       " ('cup', 387),\n",
       " ('focus', 387),\n",
       " ('issue', 387),\n",
       " ('podcast', 386),\n",
       " ('ur', 386),\n",
       " ('ceo', 385),\n",
       " ('clinton', 385),\n",
       " ('management', 385),\n",
       " ('mt', 385),\n",
       " ('problem', 385),\n",
       " ('lovely', 384),\n",
       " ('questions', 384),\n",
       " ('reports', 384),\n",
       " ('drive', 383),\n",
       " ('press', 383),\n",
       " ('rise', 383),\n",
       " ('leave', 382),\n",
       " ('piece', 382),\n",
       " ('missing', 381),\n",
       " ('v', 381),\n",
       " ('david', 380),\n",
       " ('political', 380),\n",
       " ('economy', 379),\n",
       " ('step', 379),\n",
       " ('walk', 379),\n",
       " ('la', 378),\n",
       " ('science', 378),\n",
       " ('called', 377),\n",
       " ('celebrate', 377),\n",
       " ('center', 377),\n",
       " ('results', 377),\n",
       " ('took', 377),\n",
       " ('card', 376),\n",
       " ('minister', 376),\n",
       " ('simple', 376),\n",
       " ('round', 375),\n",
       " ('least', 374),\n",
       " ('b', 373),\n",
       " ('hour', 373),\n",
       " ('idea', 373),\n",
       " ('opening', 372),\n",
       " ('waiting', 372),\n",
       " ('number', 371),\n",
       " ('value', 370),\n",
       " ('act', 369),\n",
       " ('issues', 369),\n",
       " ('met', 369),\n",
       " ('fantastic', 368),\n",
       " ('gives', 368),\n",
       " ('store', 368),\n",
       " ('16', 367),\n",
       " ('thursday', 367),\n",
       " ('tickets', 367),\n",
       " ('went', 367),\n",
       " ('register', 366),\n",
       " ('wednesday', 365),\n",
       " ('means', 364),\n",
       " ('months', 362),\n",
       " ('smart', 362),\n",
       " ('beach', 361),\n",
       " ('crisis', 361),\n",
       " ('election', 361),\n",
       " ('price', 361),\n",
       " ('artist', 360),\n",
       " ('league', 360),\n",
       " ('code', 358),\n",
       " ('role', 358),\n",
       " ('sun', 358),\n",
       " ('loved', 357),\n",
       " ('advice', 356),\n",
       " ('control', 356),\n",
       " ('low', 356),\n",
       " ('ice', 355),\n",
       " ('instagram', 355),\n",
       " ('trends', 355),\n",
       " ('bank', 354),\n",
       " ('ends', 354),\n",
       " ('kind', 354),\n",
       " ('per', 354),\n",
       " ('question', 354),\n",
       " ('weather', 354),\n",
       " ('guy', 353),\n",
       " ('thoughts', 353),\n",
       " ('wonderful', 352),\n",
       " ('workers', 352),\n",
       " ('album', 351),\n",
       " ('protect', 351),\n",
       " ('age', 350),\n",
       " ('career', 350),\n",
       " ('launch', 350),\n",
       " ('safe', 350),\n",
       " ('growing', 349),\n",
       " ('bernie', 348),\n",
       " ('boy', 348),\n",
       " ('front', 348),\n",
       " ('town', 348),\n",
       " ('clean', 347),\n",
       " ('gon', 346),\n",
       " ('onedirection', 346),\n",
       " ('shop', 346),\n",
       " ('skills', 346),\n",
       " ('reason', 345),\n",
       " ('goals', 344),\n",
       " ('helping', 344),\n",
       " ('course', 343),\n",
       " ('order', 343),\n",
       " ('0', 342),\n",
       " ('events', 342),\n",
       " ('outside', 342),\n",
       " ('understand', 342),\n",
       " ('calling', 341),\n",
       " ('write', 341),\n",
       " ('earth', 340),\n",
       " ('based', 339),\n",
       " ('bit', 338),\n",
       " ('maybe', 337),\n",
       " ('mom', 337),\n",
       " ('area', 336),\n",
       " ('hand', 336),\n",
       " ('tools', 336),\n",
       " ('healthy', 335),\n",
       " ('voting', 335),\n",
       " ('innovation', 334),\n",
       " ('successful', 334),\n",
       " ('whole', 333),\n",
       " ('director', 332),\n",
       " ('michael', 332),\n",
       " ('wef', 332),\n",
       " ('reach', 331),\n",
       " ('users', 331),\n",
       " ('apps', 330),\n",
       " ('wish', 330),\n",
       " ('cloud', 329),\n",
       " ('download', 329),\n",
       " ('email', 329),\n",
       " ('changing', 327),\n",
       " ('dog', 327),\n",
       " ('board', 326),\n",
       " ('reality', 326),\n",
       " ('rock', 326),\n",
       " ('boost', 325),\n",
       " ('cover', 324),\n",
       " ('hillaryclinton', 324),\n",
       " ('hotel', 324),\n",
       " ('powerful', 324),\n",
       " ('votes', 324),\n",
       " ('beauty', 323),\n",
       " ('cut', 323),\n",
       " ('hi', 323),\n",
       " ('signed', 323),\n",
       " ('❤️', 323),\n",
       " ('14', 322),\n",
       " ('africa', 322),\n",
       " ('fear', 322),\n",
       " ('sweet', 322),\n",
       " ('tells', 322),\n",
       " ('author', 321),\n",
       " ('catch', 321),\n",
       " ('feeling', 321),\n",
       " ('king', 321),\n",
       " ('voice', 321),\n",
       " ('happen', 320),\n",
       " ('lots', 319),\n",
       " ('process', 319),\n",
       " ('hate', 318),\n",
       " ('billion', 317),\n",
       " ('solution', 317),\n",
       " ('track', 317),\n",
       " ('eat', 316),\n",
       " ('justice', 316),\n",
       " ('match', 316),\n",
       " ('planning', 316),\n",
       " ('shares', 316),\n",
       " ('possible', 315),\n",
       " ('weeks', 315),\n",
       " ('player', 314),\n",
       " ('potus', 314),\n",
       " ('products', 314),\n",
       " ('football', 313),\n",
       " ('freedom', 313),\n",
       " ('mark', 312),\n",
       " ('offers', 312),\n",
       " ('trust', 312),\n",
       " ('govt', 311),\n",
       " ('journey', 311),\n",
       " ('wanted', 311),\n",
       " ('movie', 310),\n",
       " ('pic', 310),\n",
       " ('return', 310),\n",
       " ('economic', 309),\n",
       " ('field', 309),\n",
       " ('incredible', 309),\n",
       " ('told', 309),\n",
       " ('traffic', 309),\n",
       " ('writers', 309),\n",
       " ('agree', 308),\n",
       " ('answer', 308),\n",
       " ('due', 308),\n",
       " ('retweets', 308),\n",
       " ('tuesday', 308),\n",
       " ('european', 307),\n",
       " ('truth', 307),\n",
       " ('finds', 306),\n",
       " ('crazy', 305),\n",
       " ('families', 305),\n",
       " ('picture', 305),\n",
       " ('student', 305),\n",
       " ('tweets', 305),\n",
       " ('body', 304),\n",
       " ('style', 304),\n",
       " ('continues', 302),\n",
       " ('lose', 302),\n",
       " ('luck', 302),\n",
       " ('chris', 301),\n",
       " ('customers', 301),\n",
       " ('exclusive', 301),\n",
       " ('island', 301),\n",
       " ('lady', 301),\n",
       " ('session', 301),\n",
       " ('cost', 300),\n",
       " ('moving', 300),\n",
       " ('vs.', 300),\n",
       " ('guess', 299),\n",
       " ('quick', 299),\n",
       " ('budget', 298),\n",
       " ('works', 298),\n",
       " ('ban', 297),\n",
       " ('leadership', 297),\n",
       " ('schools', 297),\n",
       " ('supporting', 297),\n",
       " ('chat', 296),\n",
       " ('donald', 296),\n",
       " ('evening', 296),\n",
       " ('hold', 296),\n",
       " ('offer', 296),\n",
       " ('senate', 296),\n",
       " ('businesses', 295),\n",
       " ('james', 295),\n",
       " ('ok', 295),\n",
       " ('seeing', 295),\n",
       " ('stage', 295),\n",
       " ('boys', 294),\n",
       " ('difference', 294),\n",
       " ('east', 294),\n",
       " ('lessons', 293),\n",
       " ('secret', 293),\n",
       " ('send', 293),\n",
       " ('click', 292),\n",
       " ('fresh', 292),\n",
       " ('potential', 292),\n",
       " ('recent', 292),\n",
       " ('saw', 291),\n",
       " ('saying', 291),\n",
       " ('drop', 290),\n",
       " ('land', 290),\n",
       " ('message', 290),\n",
       " ('leading', 289),\n",
       " ('points', 289),\n",
       " ('poor', 289),\n",
       " ('selling', 289),\n",
       " ('wall', 289),\n",
       " ('youth', 289),\n",
       " ('2014', 288),\n",
       " ('among', 288),\n",
       " ('places', 288),\n",
       " ('account', 287),\n",
       " ('choice', 287),\n",
       " ('americans', 286),\n",
       " ('force', 286),\n",
       " ('hands', 286),\n",
       " ('draft', 285),\n",
       " ('die', 284),\n",
       " ('teams', 284),\n",
       " ('40', 283),\n",
       " ('beyond', 283),\n",
       " ('changes', 283),\n",
       " ('loving', 283),\n",
       " ('speak', 283),\n",
       " ('apply', 282),\n",
       " ('pack', 282),\n",
       " ('quality', 282),\n",
       " ('ride', 282),\n",
       " ('stars', 282),\n",
       " ('3rd', 281),\n",
       " ('along', 281),\n",
       " ('analysis', 281),\n",
       " ('college', 281),\n",
       " ('dark', 281),\n",
       " ('military', 281),\n",
       " ('environment', 280),\n",
       " ('featuring', 280),\n",
       " ('june', 280),\n",
       " ('missed', 280),\n",
       " ('rain', 280),\n",
       " ('thx', 280),\n",
       " ('coach', 279),\n",
       " ('debate', 279),\n",
       " ('foreign', 279),\n",
       " ('happened', 279),\n",
       " ('source', 279),\n",
       " ('within', 279),\n",
       " ('christmas', 278),\n",
       " ('excellent', 278),\n",
       " ('information', 278),\n",
       " ('instead', 278),\n",
       " ('ladies', 278),\n",
       " ('double', 277),\n",
       " ('financial', 277),\n",
       " ('raise', 277),\n",
       " ('son', 277),\n",
       " ('60', 276),\n",
       " ('chief', 276),\n",
       " ('french', 276),\n",
       " ('paid', 276),\n",
       " ('personal', 276),\n",
       " ('rate', 276),\n",
       " ('brilliant', 275),\n",
       " ('coffee', 275),\n",
       " ('including', 275),\n",
       " ('discuss', 274),\n",
       " ('member', 274),\n",
       " ('players', 274),\n",
       " ('views', 274),\n",
       " ('investment', 273),\n",
       " ('later', 273),\n",
       " ('product', 273),\n",
       " ('sad', 273),\n",
       " ('van', 273),\n",
       " ('violence', 273),\n",
       " ('21', 272),\n",
       " ('24', 272),\n",
       " ('helps', 272),\n",
       " ('largest', 272),\n",
       " ('rest', 272),\n",
       " ('continue', 271),\n",
       " ('taken', 271),\n",
       " ('afternoon', 270),\n",
       " ('paper', 270),\n",
       " ('18', 269),\n",
       " ('creative', 269),\n",
       " ('ft', 269),\n",
       " ('parents', 269),\n",
       " ('positive', 269),\n",
       " ('title', 269),\n",
       " ('winners', 269),\n",
       " ('fashion', 268),\n",
       " ('funding', 268),\n",
       " ('projects', 268),\n",
       " ('collection', 267),\n",
       " ('speech', 267),\n",
       " ('box', 266),\n",
       " ('female', 266),\n",
       " ('private', 266),\n",
       " ('ebay', 265),\n",
       " ('plus', 265),\n",
       " ('released', 265),\n",
       " ('san', 265),\n",
       " ('android', 264),\n",
       " ('discover', 264),\n",
       " ('festival', 264),\n",
       " ('hits', 264),\n",
       " ('nyc', 264),\n",
       " ('prize', 264),\n",
       " ('snow', 264),\n",
       " ('systems', 264),\n",
       " ('score', 263),\n",
       " ('software', 263),\n",
       " ('50+', 262),\n",
       " ('benefits', 262),\n",
       " ('cause', 262),\n",
       " ('clear', 262),\n",
       " ('loss', 262),\n",
       " ('able', 261),\n",
       " ('berniesanders', 261),\n",
       " ('judge', 261),\n",
       " ('nation', 261),\n",
       " ('leehillerlondon', 260),\n",
       " ('sanders', 260),\n",
       " ('stuff', 260),\n",
       " ('avoid', 259),\n",
       " ('bbc', 259),\n",
       " ('dear', 259),\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks_ctr.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save out top 10000 words\n",
    "with open('/usr2/mamille2/twitter/data/huang2016_data/train_text_vocab_10k.txt', 'w') as f:\n",
    "    for w in vocab_10k:\n",
    "        f.write(w + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "19.0129045454\n"
     ]
    }
   ],
   "source": [
    "# See number of words in tweets\n",
    "tweet_lens = [len(d) for d in toks]\n",
    "print(max(tweet_lens))\n",
    "print(np.mean(tweet_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save out word embeddings for vocab\n",
    "wembed10k = {w: wembed[w] for w in vocab_10k}\n",
    "\n",
    "with open('/usr2/mamille2/twitter/data/huang2016_data/train_vocab_10k_emb.pkl', 'wb') as f:\n",
    "    pickle.dump(wembed10k, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_tweet(t):\n",
    "    return [wd for wd in t if not wd in stops and not any([s in wd for s in stop_pats])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20e189fc9974a24858abc4bd1bf6060"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "215118\n",
      "214999\n",
      "['rt', 'walmsley_liz', 'morning', 'becky', 'might', 'surprised', 'know', 'going', 'walk', 'recce']\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed tweet texts\n",
    "toks = toks_train\n",
    "toks_p = []\n",
    "\n",
    "for d in tqdm(toks):\n",
    "#     toks_p.append([t for t in d if t in vocab_all])\n",
    "    d_p = preprocess_tweet(d)\n",
    "    if len(d_p) > 0:\n",
    "        toks_p.append(d_p)\n",
    "\n",
    "print(len(toks_train))\n",
    "print(len(toks_p))\n",
    "print(toks_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/usr2/mamille2/twitter/data/huang2016_data/text_train.txt', 'w') as f:\n",
    "    for d in toks_p:\n",
    "        f.write(' '.join(d) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel wembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet2vec(tweet_toks, max_len):\n",
    "    \"\"\" Converts tags to indices, truncating and padding to length 5 (largest number of tags in the dataset is 4) \"\"\"\n",
    "    emb_list = [wembed10k[w] for w in tweet_toks[:max_len]]\n",
    "    tweet_mat = np.pad(emb_list, ((0,max_len-len(emb_list)), (0,0)), 'constant', constant_values=0)\n",
    "    \n",
    "    return tweet_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 300)\n",
      "[[ 0.07404656 -0.16057926 -0.18220727 ..., -0.16359863 -0.10331138\n",
      "   0.11113211]\n",
      " [-0.03699651 -0.20341067  0.00335062 ..., -0.04462308  0.49036312\n",
      "  -0.69343126]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "eg = tweet2vec(['example', 'tweet'], MAX_LEN)\n",
    "print(eg.shape)\n",
    "print(eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-507ca333fb6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get matrices for tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweetmats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_no_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtweet2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:66124)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-507ca333fb6d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get matrices for tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweetmats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_no_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtweet2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-821bac1c109a>\u001b[0m in \u001b[0;36mtweet2vec\u001b[0;34m(tweet_toks, max_len)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\" Converts tags to indices, truncating and padding to length 5 (largest number of tags in the dataset is 4) \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0memb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwembed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet_toks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtweet_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtweet_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m   1289\u001b[0m            [10, 10, 10, 10, 10, 10, 10]])\n\u001b[1;32m   1290\u001b[0m     \"\"\"\n\u001b[0;32m-> 1291\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`pad_width` must be of integral type.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tweetmats_train = train_data['text_no_tags'].map(lambda x: tweet2vec(x, MAX_LEN)) # bad idea--too much memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
